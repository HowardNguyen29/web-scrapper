{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement\n",
    "1. Write a python script to pull some required information from a web page\n",
    "\n",
    "2. Clean the pulled informationand store it in a csv file\n",
    "\n",
    "3. The python script should take url as input and output the csv file with pulled, cleaned required information.\n",
    "\n",
    "Name of the restaurant\n",
    "\n",
    "How many reviews are there in total\n",
    "\n",
    "Reviews\n",
    "\n",
    "  - Review_text\n",
    "\n",
    "  - Reviewer\n",
    "\n",
    "  - Rating\n",
    "\n",
    "\n",
    "\n",
    "Create a csv file with the above details.\n",
    "\n",
    "Bonus: If you can extend the above script to crawl multiple restaurant pages, pull all the above review information and write them into a csv file, you will get bonus marks. Very tough!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label = aria-label\n",
    "#  undefined list__09f24__ynIEd\n",
    "# Comment class =  css-1q2nwpv\n",
    "\n",
    "#  css-1q2nwpv. css-1qn0b6x\n",
    "#       Rating: . css-10n911v   ... .five-stars__09f24__mBKym\n",
    "#       Comment: . css-9ul5p9.comment__09f24__D0cxf css-qgunke. raw__09f24__T4Ezm   <- Content of this /span\n",
    "#       Name: . css-174a15u.css-1w3ky6t.css-1u1p5a2. css-1qn0b6x   <- aria-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter url of a medium article: \n",
      "<p class=\"css-foyide\">102 reviews</p>\n",
      "CSV file saved to: restaurant_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.yelp.ca/biz/pho-con-bo-north-york?page_src=related_bizes\"\n",
    "\n",
    "def get_page():\n",
    "    global url\n",
    "    \n",
    "    print('Enter url of a medium article: ')\n",
    "    # url = input()\n",
    "    # if url is None:\n",
    "    url = URL\n",
    "    if not re.match(r'https?://www.yelp.ca/',url):\n",
    "        print('Please enter a valid website, or make sure it is a yelp url')\n",
    "        sys.exit(1)\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def clean(text):\n",
    "    rep = {\"<br>\": \"\\n\", \"<br/>\": \"\\n\", \"<li>\":  \"\\n\"}\n",
    "    rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "    pattern = re.compile(\"|\".join(rep.keys()))\n",
    "    text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)\n",
    "    text = re.sub('\\<(.*?)\\>', '', text)\n",
    "    return text\n",
    "\n",
    "def collect_text(soup):\n",
    "    text = f'url: {url}\\n\\n'\n",
    "    para_text = soup.find_all('p')\n",
    "    print(f\"paragraphs text = \\n {para_text}\")\n",
    "    for para in para_text:\n",
    "        text += f\"{para.text}\\n\\n\"\n",
    "    return text\n",
    "\n",
    "def collect_name_res(soup):\n",
    "\n",
    "    restaurant_text = soup.find(\"h1\")\n",
    "    restaurant_name = restaurant_text.text.strip()\n",
    "    # url_parts = url.split(\"/biz/\")\n",
    "    # restaurant_name_parts = url_parts[1].split(\"-\")\n",
    "    # restaurant_name = \" \".join(restaurant_name_parts[:-1])\n",
    "\n",
    "    return restaurant_name\n",
    "\n",
    "def collect_the_total_review(soup):\n",
    "    reviews_element = soup.find(\"p\", class_=\"css-foyide\")\n",
    "    print(reviews_element)\n",
    "    reviews_text = reviews_element.text.split(' ')[0]\n",
    "    return reviews_text\n",
    "\n",
    "def collect_name(soup):\n",
    "    text = []\n",
    "    name_text = soup.select('div[class*=\"user-passport-info\"] span[class*=\"fs-block\"] a')\n",
    "    for name in name_text:\n",
    "        val = name.text\n",
    "        text.append(val)\n",
    "    return text\n",
    "\n",
    "def collect_review(soup):\n",
    "    text = []\n",
    "    name_text = soup.select('p[class*=\"comment__09f24__D0cxf\"] span')\n",
    "    for name in name_text:\n",
    "        val = name.text\n",
    "        text.append(val)\n",
    "    return text\n",
    "\n",
    "def collect_stars(soup):\n",
    "    text = []\n",
    "    # name_text = soup.select('span[class*=\" css-1d8srnw\"] div[class*=\"stars__09f24__mBKym\"]')\n",
    "    name_text = soup.select('#reviews > section > div.css-1qn0b6x > ul > li > div > div.css-10n911v > div > div > span > div')\n",
    "    for name in name_text:\n",
    "        val = name['aria-label']\n",
    "        text.append(val)\n",
    "    return text\n",
    "\n",
    "def save_file(text):\n",
    "    if not os.path.exists('./scraped_articles'):\n",
    "        os.mkdir('./scraped_articles')\n",
    "    name = url.split(\"/\")[-1]\n",
    "    print(name)\n",
    "    fname = f'scraped_articles/{name}.txt'\n",
    "    with open(fname, 'w') as file:\n",
    "        file.write(text)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    page = get_page()\n",
    "    # text = collect_text(get_page())\n",
    "    res_name = collect_name_res(page)\n",
    "    total_review = collect_the_total_review(page)\n",
    "    names_customer = collect_name(page)\n",
    "    reviews_customer = collect_review(page)\n",
    "    stars_customer = collect_stars(page)\n",
    " \n",
    "    # Define the data\n",
    "    # Create a list of lists to represent the CSV data\n",
    "    csv_data = [\n",
    "        [\"restaurant name\", res_name],\n",
    "        [\"total review\", total_review],\n",
    "        names_customer,\n",
    "        reviews_customer,\n",
    "        stars_customer\n",
    "    ]\n",
    "\n",
    "    # Define the output file path\n",
    "    output_csv_path = \"restaurant_reviews.csv\"\n",
    "\n",
    "    # Write the CSV data to the file\n",
    "    with open(output_csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(csv_data)\n",
    "\n",
    "    print(f\"CSV file saved to: {output_csv_path}\")\n",
    "\n",
    "    # Code ends here\n",
    "    # save_file(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
